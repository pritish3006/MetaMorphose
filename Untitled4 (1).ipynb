{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "t5Xr3AGjuRGb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution - (c:\\python310\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution - (c:\\python310\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution - (c:\\python310\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution - (c:\\python310\\lib\\site-packages)\n",
            "WARNING: You are using pip version 22.0.4; however, version 22.3.1 is available.\n",
            "You should consider upgrading via the 'c:\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
          ]
        }
      ],
      "source": [
        "%pip install -q tfds-nightly tensorflow matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ShM3fQVBx6Vm"
      },
      "outputs": [],
      "source": [
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "01DDZW2C6asK"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Python310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "import random\n",
        "import numpy as np\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "DD6vI1h1k5oN"
      },
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "(unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape (271574283.py, line 1)",
          "output_type": "error",
          "traceback": [
            "\u001b[1;36m  Cell \u001b[1;32mIn [11], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    dl_manager = tfds.download.DownloadManager(download_dir=\"C:\\Users\\18042\\Documents\\Senior Project\")\u001b[0m\n\u001b[1;37m                                                                                                     ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape\n"
          ]
        }
      ],
      "source": [
        "dl_manager = tfds.download.DownloadManager(download_dir=\"C:\\Users\\18042\\Documents\\Senior Project\")\n",
        "extracted_path=dl_manager.extract(\"Senior Project\\goblin_images.zip\")\n",
        "print(\"test 1\")\n",
        "path = os.path.join(str(extracted_path) + '\\images\\test')\n",
        "image = os.listdir(path)[0]\n",
        "array1=tf.keras.utils.img_to_array(Image.open(os.path.join(path, image)))\n",
        "print(\"test 2\")\n",
        "array1=tf.cast(array1, dtype=tf.uint8)\n",
        "def generator(path1):\n",
        "    for image in os.listdir(path1):\n",
        "      image_id = image.split(\".\")[0]\n",
        "      array1=tf.keras.utils.img_to_array(Image.open(os.path.join(path1, image)))\n",
        "      array1=tf.cast(array1, dtype=tf.uint8)\n",
        "      yield image_id, {\n",
        "        \"image\": array1,\n",
        "        \"label\": tf.cast(tf.constant(0), dtype=tf.int64),\n",
        "      }\n",
        "\n",
        "train = generator(path)\n",
        "#train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7qVAo1v-7B_v"
      },
      "outputs": [],
      "source": [
        "class GoblinDataset(tfds.core.GeneratorBasedBuilder):\n",
        "  \"\"\" Dataset builder for GoblinDataset \"\"\"\n",
        "\n",
        "  VERSION = tfds.core.Version('1.0.0')\n",
        "  RELEASE_NOTES = {\n",
        "       '1.0.0': 'Initial Release.',\n",
        "  }\n",
        "\n",
        "  def _info(self):\n",
        "    return tfds.core.DatasetInfo(\n",
        "      builder=self,\n",
        "      name='Goblin Dataset',\n",
        "      #full_name='cycle_gan/goblin/1.0.0',\n",
        "      # Description and homepage used for documentation\n",
        "      description=\"\"\"\n",
        "      This is the goblin image dataset\n",
        "      \"\"\",\n",
        "      homepage='https://www.kaggle.com/datasets/jerimee/goblin-portraits',\n",
        "      features=tfds.features.FeaturesDict({\n",
        "          #'image_description': tfds.features.Text(),\n",
        "          'image': tfds.features.Image(shape=(512, 512, 3), dtype=tf.uint8),\n",
        "          'label': tfds.features.ClassLabel(shape=(), dtype=tf.int64, num_classes=1),\n",
        "      }),\n",
        "      # If there's a common `(input, target)` tuple from the features,\n",
        "      # specify them here. They'll be used if as_supervised=True in\n",
        "      # builder.as_dataset.\n",
        "      supervised_keys=('image', 'label'),\n",
        "      # Specify whether to disable shuffling on the examples. Set to False by default.\n",
        "      disable_shuffling=False,\n",
        "      #the split information, if necessary cut it out\n",
        "      # splits={\n",
        "      #     'train': <SplitInfo num_examples=563, num_shards=1>,\n",
        "      #     'test': <SplitInfo num_examples=187, num_shards=1>,\n",
        "      # }\n",
        "      # Bibtex citation for the dataset\n",
        "      citation=r\"\"\"\n",
        "      Public domain\n",
        "      \"\"\",\n",
        "    )\n",
        "\n",
        "    def _split_generators(self, dl_manager = tfds.download.DownloadManager(download_dir='/content')):\n",
        "        \"\"\"Download the data and define splits.\"\"\"\n",
        "        extracted_path = dl_manager.extract('goblin_images.zip') ## This needs to be tuned for our datasets\n",
        "        \n",
        "        # dl_manager returns pathlib-like objects with `path.read_text()`,\n",
        "        # `path.iterdir()`,...\n",
        "        return {\n",
        "            'train': self._generate_examples(str(extracted_path) + '/images/train'),\n",
        "            'test': self._generate_examples(str(extracted_path) + '/images/test'),\n",
        "        }\n",
        "    \n",
        "    def _generate_examples(self, path):\n",
        "      for image in os.listdir(path1):\n",
        "        image_id = image.split(\".\")[0]\n",
        "        array1=tf.keras.utils.img_to_array(Image.open(os.path.join(path1, image)))\n",
        "        array1=tf.cast(array1, dtype=tf.uint8)\n",
        "        yield image_id, {\n",
        "          \"image\": array1,\n",
        "          \"label\": tf.cast(tf.constant(0), dtype=tf.int64),\n",
        "     }\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gRiycxC0BBQ1"
      },
      "outputs": [],
      "source": [
        "!mkdir datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HstIuiUpConz",
        "outputId": "5933014e-1783-491f-e3b4-16a037a790db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/datasets\n"
          ]
        }
      ],
      "source": [
        "%cd datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fH1XD7YuGBh_",
        "outputId": "c7930471-623c-454a-e78c-21299b1a542c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/datasets\n"
          ]
        }
      ],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wOFulUnoDBcJ",
        "outputId": "0058a9eb-3db0-4771-8562-2066c5d2f8f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-11-02 22:44:26.781712: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "Dataset generated at /content/datasets/GoblinDataset\n",
            "You can start searching `TODO(GoblinDataset)` to complete the implementation.\n",
            "Please check https://www.tensorflow.org/datasets/add_dataset for additional details.\n"
          ]
        }
      ],
      "source": [
        "!tfds new GoblinDataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nXOWyUvd_BEm",
        "outputId": "4c56f34b-9013-43ca-f970-57d7e6ead6de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/bin/bash: -c: line 0: syntax error near unexpected token `GoblinDataset'\n",
            "/bin/bash: -c: line 0: `TODO(GoblinDataset)'\n"
          ]
        }
      ],
      "source": [
        "!TODO(GoblinDataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5LYalEtMDI7M",
        "outputId": "1b1f56a0-e65b-4749-ad90-963e4579dc6f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/datasets/GoblinDataset\n"
          ]
        }
      ],
      "source": [
        "%cd GoblinDataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GN8kBlkWDRSr"
      },
      "outputs": [],
      "source": [
        "!tfds build"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uIuh5QsfseTh"
      },
      "outputs": [],
      "source": [
        "#everything past this point is trying to build with keras.preprocesssing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6jAbYkzztY3i"
      },
      "outputs": [],
      "source": [
        "# import numpy as np\n",
        "# import tensorflow as tf\n",
        "# from tensorflow import keras\n",
        "# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "# import zipfile\n",
        "# import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oqVS3sKLuLB1"
      },
      "outputs": [],
      "source": [
        "# with zipfile.ZipFile(\"/content/goblin_images.zip\", 'r') as zip_ref:\n",
        "#     zip_ref.extractall(\"/content/goblin_images\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NB1Z9yjWtdRr",
        "outputId": "0998dac0-06a7-47e2-cc2f-d0dfb3e17c40"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 600 images belonging to 1 classes.\n",
            "Found 150 images belonging to 1 classes.\n",
            "Found 150 images belonging to 1 classes.\n"
          ]
        }
      ],
      "source": [
        "# image_size = (512,512)\n",
        "# batch_size = 1\n",
        "# dataset_path = '/content/goblin_images'\n",
        "\n",
        "# train_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
        "\n",
        "# train_batches = train_datagen.flow_from_directory(\n",
        "#         dataset_path,\n",
        "#         target_size=image_size,\n",
        "#         batch_size=batch_size,\n",
        "#         class_mode='binary',\n",
        "#         subset='training')\n",
        "\n",
        "\n",
        "# validation_batches = train_datagen.flow_from_directory(\n",
        "#         dataset_path,\n",
        "#         target_size=image_size,\n",
        "#         batch_size=batch_size,\n",
        "#         class_mode='binary',\n",
        "#         subset='validation')\n",
        "\n",
        "\n",
        "# test_batches = train_datagen.flow_from_directory(\n",
        "#         dataset_path,\n",
        "#         target_size=image_size,\n",
        "#         batch_size=batch_size,\n",
        "#         class_mode='binary', \n",
        "#         shuffle=False,\n",
        "#         subset='validation')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ocdfdgv4wWJ9"
      },
      "outputs": [],
      "source": [
        "#iter(train_batches)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.10.0 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
